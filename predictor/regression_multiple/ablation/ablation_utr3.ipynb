{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f45815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T13:25:21.855899Z",
     "iopub.status.busy": "2024-08-26T13:25:21.855507Z",
     "iopub.status.idle": "2024-08-26T13:25:27.729767Z",
     "shell.execute_reply": "2024-08-26T13:25:27.729170Z",
     "shell.execute_reply.started": "2024-08-26T13:25:21.855866Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import math\n",
    "import time\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.auto import tqdm as tqdm_auto\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1cc66fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T13:25:27.731117Z",
     "iopub.status.busy": "2024-08-26T13:25:27.730834Z",
     "iopub.status.idle": "2024-08-26T13:25:27.735251Z",
     "shell.execute_reply": "2024-08-26T13:25:27.734826Z",
     "shell.execute_reply.started": "2024-08-26T13:25:27.731102Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../../model\")\n",
    "import utrdata_cl as utrdata\n",
    "from legnet import LegNetClassifier\n",
    "from pl_regressor import RNARegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1a13f6-1302-4e60-981e-3874e6548a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T13:25:27.736012Z",
     "iopub.status.busy": "2024-08-26T13:25:27.735863Z",
     "iopub.status.idle": "2024-08-26T13:25:27.740120Z",
     "shell.execute_reply": "2024-08-26T13:25:27.739412Z",
     "shell.execute_reply.started": "2024-08-26T13:25:27.735998Z"
    }
   },
   "outputs": [],
   "source": [
    "UTR_TYPE = \"utr3\"\n",
    "SEQSIZE = 50 if UTR_TYPE == \"utr5\" else 240"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e499667-0eae-4e02-8908-5b1344c4032c",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3929a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T13:25:27.740889Z",
     "iopub.status.busy": "2024-08-26T13:25:27.740726Z",
     "iopub.status.idle": "2024-08-26T13:25:28.273798Z",
     "shell.execute_reply": "2024-08-26T13:25:28.273080Z",
     "shell.execute_reply.started": "2024-08-26T13:25:27.740873Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ablation_utils import load_data\n",
    "\n",
    "splits = load_data(utr_type=UTR_TYPE, prefix=\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec976669-ec8f-418b-81af-ac737735da83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T13:25:28.274687Z",
     "iopub.status.busy": "2024-08-26T13:25:28.274529Z",
     "iopub.status.idle": "2024-08-26T13:25:28.278235Z",
     "shell.execute_reply": "2024-08-26T13:25:28.277522Z",
     "shell.execute_reply.started": "2024-08-26T13:25:28.274673Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "steps_per_epoch = max(1, splits[\"train\"].shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8034baf-7f7d-4032-859d-d8f337c2898d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T13:25:28.278860Z",
     "iopub.status.busy": "2024-08-26T13:25:28.278728Z",
     "iopub.status.idle": "2024-08-26T13:25:28.281942Z",
     "shell.execute_reply": "2024-08-26T13:25:28.281403Z",
     "shell.execute_reply.started": "2024-08-26T13:25:28.278847Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_workers = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7586065-f11c-4319-9b50-8ad620da703b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T13:25:28.283710Z",
     "iopub.status.busy": "2024-08-26T13:25:28.283424Z",
     "iopub.status.idle": "2024-08-26T13:25:28.296569Z",
     "shell.execute_reply": "2024-08-26T13:25:28.295888Z",
     "shell.execute_reply.started": "2024-08-26T13:25:28.283691Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def launch_model(\n",
    "    model_name: str,\n",
    "    seed: int,\n",
    "    train_ds_kws: dict,\n",
    "    val_ds_kws: dict,\n",
    "    model_class,\n",
    "    model_kws: dict,\n",
    "    criterion_class,\n",
    "    criterion_kws: dict,\n",
    "    optimizer_class,\n",
    "    optimizer_kws: dict,\n",
    "    lr_scheduler_class,\n",
    "    lr_scheduler_kws: dict,\n",
    "    test_time_validation: bool,\n",
    "    epochs: int,\n",
    "):\n",
    "    pl.seed_everything(seed)\n",
    "\n",
    "    # Creating Datasets\n",
    "    train_set = utrdata.UTRData(\n",
    "        df=splits[\"train\"],\n",
    "        **train_ds_kws,\n",
    "    )\n",
    "    val_set = utrdata.UTRData(\n",
    "        df=splits[\"val\"],\n",
    "        **val_ds_kws,\n",
    "    )\n",
    "    test_set = utrdata.UTRData(\n",
    "        df=splits[\"test\"],\n",
    "        **val_ds_kws,\n",
    "    )\n",
    "\n",
    "    assert train_set.num_channels == val_set.num_channels\n",
    "    try:\n",
    "        div_factor = val_ds_kws[\"augment_kws\"][\"shift_left\"] + \\\n",
    "                     val_ds_kws[\"augment_kws\"][\"shift_right\"] + 1\n",
    "    except KeyError:\n",
    "        div_factor = 1\n",
    "\n",
    "    # Creating DataLoaders\n",
    "    dl_train = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    # dl_train = utrdata.DataLoaderWrapper(dl_train, batch_per_epoch=batch_per_epoch)\n",
    "    dl_val = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size // div_factor,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "    dl_test = DataLoader(\n",
    "        test_set,\n",
    "        batch_size=batch_size // div_factor,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    model = RNARegressor(\n",
    "        model_class=model_class,\n",
    "        model_kws=model_kws | dict(\n",
    "            in_channels=train_set.num_channels\n",
    "        ),\n",
    "        criterion_class=criterion_class,\n",
    "        criterion_kws=criterion_kws,\n",
    "        optimizer_class=optimizer_class,\n",
    "        optimizer_kws=optimizer_kws,\n",
    "        lr_scheduler_class=lr_scheduler_class,\n",
    "        lr_scheduler_kws=lr_scheduler_kws,\n",
    "        test_time_validation=test_time_validation,\n",
    "    )\n",
    "    model.model_name = model_name\n",
    "\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=f\"saved_models/{UTR_TYPE}_{model_name}/seed={seed:02d}/\",\n",
    "        save_top_k=1,\n",
    "        save_last=False,\n",
    "        monitor=\"val_pearson_r_0\",\n",
    "        mode=\"max\"\n",
    "    )\n",
    "    progressbar_callback = pl.callbacks.TQDMProgressBar(refresh_rate=0.5)\n",
    "\n",
    "    logger = pl.loggers.tensorboard.TensorBoardLogger(\"tb_logs\", name=model.model_name)\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[checkpoint_callback, progressbar_callback],\n",
    "        logger=logger,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        deterministic=True,\n",
    "        max_epochs=epochs,\n",
    "        num_sanity_val_steps=0,\n",
    "        # gradient_clip_val=1e-5,\n",
    "        # gradient_clip_algorithm=\"norm\",\n",
    "    )\n",
    "    trainer.fit(model=model, train_dataloaders=dl_train, val_dataloaders=dl_val)\n",
    "    best_model = RNARegressor.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "\n",
    "    prediction = trainer.predict(model=best_model, dataloaders=dl_test)\n",
    "    test_pred, test_real = zip(*prediction)\n",
    "    test_pred = torch.concat(test_pred).numpy()\n",
    "    test_real = torch.concat(test_real).numpy()\n",
    "    test_mass_center_pred = test_pred[:, -1]  # Last (or the only) column should contain the predicted mass center\n",
    "    test_mass_center_real = test_real[:, -1]\n",
    "    test_df = splits[\"test\"].copy()\n",
    "    assert np.allclose(test_df[\"mass_center\"].values, test_mass_center_real)\n",
    "    test_df[\"pred_mass_center\"] = test_mass_center_pred\n",
    "\n",
    "    metrics_ct = list()\n",
    "    cell_types = [\"all\"]\n",
    "    cell_types.extend(test_set.celltype_codes.keys())\n",
    "    for ct in cell_types:\n",
    "        if ct == \"all\":\n",
    "            grouping = test_df.groupby(\"seq\")\n",
    "            real = grouping[\"mass_center\"].mean()\n",
    "            pred = grouping[\"pred_mass_center\"].mean()\n",
    "        else:\n",
    "            ct_filter = test_df[\"cell_type\"] == ct\n",
    "            real = test_df.loc[ct_filter, \"mass_center\"]\n",
    "            pred = test_df.loc[ct_filter, \"pred_mass_center\"]\n",
    "        r = ss.pearsonr(pred, real)\n",
    "        rho = ss.spearmanr(pred, real)\n",
    "        metrics = {\n",
    "            \"model\": model_name,\n",
    "            \"cell type\": ct,\n",
    "            \"seed\": seed,\n",
    "            \"pearsonr\": r.statistic,\n",
    "            \"pearsonr_pvalue\": r.pvalue,\n",
    "            \"spearmanr\": rho.statistic,\n",
    "            \"spearmanr_pvalue\": rho.pvalue,\n",
    "        }\n",
    "        metrics_ct.append(metrics)\n",
    "\n",
    "    return metrics_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb5cb0-5937-48cf-bc3d-e3121da19b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parameter_ablation(\n",
    "    model_name: str,\n",
    "    parameter_update: dict,\n",
    "):\n",
    "    checked = {\n",
    "        \"seed\": range(0, 30),\n",
    "        \"features\": [\n",
    "            # (\"sequence\", \"revcomp\", \"intensity\", \"positional\", \"conditions\"),\n",
    "            (\"sequence\", \"positional\", \"conditions\"),\n",
    "        ],\n",
    "        \"augment_dict\": [\n",
    "            dict(\n",
    "                extend_left=0,\n",
    "                extend_right=0,\n",
    "                shift_left=0,\n",
    "                shift_right=0,\n",
    "                revcomp=False,\n",
    "            ),\n",
    "        ],\n",
    "        \"epochs\": [10],\n",
    "        \"predict_cols\": [['diff', 'mass_center']],\n",
    "    }\n",
    "    checked.update(parameter_update)\n",
    "\n",
    "    METRICS = list()\n",
    "\n",
    "    for subset in itertools.product(\n",
    "        *checked.values()\n",
    "    ):\n",
    "        PARAMS = dict(zip(checked.keys(), subset))\n",
    "        AUGMENT_KEY = any(PARAMS[\"augment_dict\"].values())\n",
    "        AUGMENT_TEST_TIME = AUGMENT_KEY\n",
    "\n",
    "        metrics = launch_model(\n",
    "            model_name=model_name,\n",
    "            seed=PARAMS[\"seed\"],\n",
    "            train_ds_kws=dict(\n",
    "                predict_cols=PARAMS[\"predict_cols\"],\n",
    "                construct_type=UTR_TYPE,\n",
    "                features=PARAMS[\"features\"],  # (\"sequence\", \"conditions\", \"positional\", \"revcomp\")\n",
    "                augment=AUGMENT_KEY,\n",
    "                augment_test_time=False,\n",
    "                augment_kws=PARAMS[\"augment_dict\"],\n",
    "            ),\n",
    "            val_ds_kws=dict(\n",
    "                predict_cols=PARAMS[\"predict_cols\"],\n",
    "                construct_type=UTR_TYPE,\n",
    "                features=PARAMS[\"features\"],  # (\"sequence\", \"conditions\", \"positional\", \"revcomp\")\n",
    "                augment=False,\n",
    "                augment_test_time=AUGMENT_TEST_TIME,\n",
    "                augment_kws=PARAMS[\"augment_dict\"],\n",
    "            ),\n",
    "            model_class=LegNetClassifier,\n",
    "            model_kws=dict(\n",
    "                seqsize=SEQSIZE,\n",
    "                ks=3,\n",
    "                out_channels=PARAMS[\"predict_cols\"].__len__(),\n",
    "                conv_sizes=(128, 64, 64, 32, 32),\n",
    "                mapper_size=256,\n",
    "                linear_sizes=None,\n",
    "                use_max_pooling=False,\n",
    "                final_activation=nn.Identity\n",
    "            ),\n",
    "            criterion_class=nn.MSELoss,\n",
    "            criterion_kws=dict(),\n",
    "            optimizer_class=torch.optim.AdamW,\n",
    "            optimizer_kws=dict(\n",
    "                # lr=0.01,\n",
    "                weight_decay=0.1,\n",
    "            ),\n",
    "            lr_scheduler_class=torch.optim.lr_scheduler.OneCycleLR,\n",
    "            lr_scheduler_kws=dict(\n",
    "                max_lr=0.01,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=PARAMS[\"epochs\"],\n",
    "                pct_start=0.3,\n",
    "                three_phase=False,\n",
    "                cycle_momentum=True,\n",
    "            ),\n",
    "            test_time_validation=AUGMENT_TEST_TIME,\n",
    "            epochs=PARAMS[\"epochs\"],\n",
    "        )\n",
    "        METRICS.append(metrics)\n",
    "    return METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadfb347-3d1e-4531-843b-6844f3f73078",
   "metadata": {},
   "source": [
    "## Launching ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e925e-6169-458f-9ce9-6f303474e5ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ablation_tests = {\n",
    "    \"NoChanges\": {},\n",
    "    \"RemovedDiff\": {\n",
    "        \"predict_cols\": [['mass_center']],\n",
    "    },\n",
    "    \"RemovedPositionalEncoding\": {\n",
    "        \"features\": [\n",
    "            (\"sequence\", \"conditions\"),\n",
    "        ],\n",
    "    },\n",
    "    \"RemovedDiffAndPositionalEncoding\": {\n",
    "        \"predict_cols\": [['mass_center']],\n",
    "        \"features\": [\n",
    "            (\"sequence\", \"conditions\"),\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "ablation_metrics = list()\n",
    "for test_name, update_dict in ablation_tests.items():\n",
    "    iter_metrics = parameter_ablation(model_name=test_name, parameter_update=update_dict)\n",
    "    ablation_metrics.extend(iter_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159fd523-6c88-4c5a-90f9-6a4c4e029093",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-26T13:25:59.345243Z",
     "iopub.status.idle": "2024-08-26T13:25:59.345440Z",
     "shell.execute_reply": "2024-08-26T13:25:59.345352Z",
     "shell.execute_reply.started": "2024-08-26T13:25:59.345342Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"{UTR_TYPE}_ablation.json\", \"wt\") as handle:\n",
    "    json.dump(ablation_metrics, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e1e23",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "64b0dffe91cf8f88d3a84eea1f79c78b7512619aa8cb3e6f3df2fb7199efc743"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
